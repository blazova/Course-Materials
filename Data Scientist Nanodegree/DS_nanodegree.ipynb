{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Software Engineering Practices\n",
    "\n",
    "\n",
    "This lesson uses classroom workspaces that contain all of the files and functionality you will need. You can also find the files in the data scientist nanodegree term 2 GitHub repo.\n",
    "https://github.com/udacity/DSND_Term2/tree/master/lessons/ObjectOrientedProgramming\n",
    "\n",
    "\n",
    "PRODUCTION CODE: software running on production servers to handle live users and data of the intended audience. Note this is different from production quality code, which describes code that meets expectations in reliability, efficiency, etc., for production. Ideally, all code in production meets these expectations, but this is not always the case.\n",
    "\n",
    "CLEAN: readable, simple, and concise. A characteristic of production quality code that is crucial for collaboration and maintainability in software development.\n",
    "\n",
    "MODULAR: logically broken up into functions and modules. Also an important characteristic of production quality code that makes your code more organized, efficient, and reusable. \n",
    "- DRY (don't repeat yourself).\n",
    "- Abstraction\n",
    "- Minimize the number of entities (functions, classes, modules)\n",
    "- Functions should do 1 thing\n",
    "- Arbitrary variable names can be more effective in certain functions (`for i in list...`)\n",
    "\n",
    "\n",
    "\n",
    "MODULE: a file. Modules allow code to be reused by encapsulating them into files that can be imported into other files.\n",
    "\n",
    "\n",
    "## Refactoring Code\n",
    "\n",
    "restructuring your code to improve its internal structure, without changing its external functionality. This gives you a chance to clean and modularize your program after you've got it working.\n",
    "\n",
    "\n",
    "Since it isn't easy to write your best code while you're still trying to just get it working, allocating time to do this is essential to producing high quality code. Despite the initial time and effort required, this really pays off by speeding up your development time in the long run.\n",
    "\n",
    "Example notebook:\n",
    "\n",
    "df with columns: \tfixed acidity\tvolatile acidity\tcitric acid\tresidual sugar\tchlorides\tfree sulfur dioxide\ttotal sulfur dioxide\tdensity\tpH\tsulphates\talcohol\tquality\n",
    "\n",
    "\n",
    "```def numeric_to_buckets(df, column_name):\n",
    "    median = df[column_name].median()\n",
    "    for i, val in enumerate(df[column_name]):\n",
    "        if val >= median:\n",
    "            df.loc[i, column_name] = 'high'\n",
    "        else:\n",
    "            df.loc[i, column_name] = 'low' \n",
    "\n",
    "for feature in df.columns[:-1]:\n",
    "    numeric_to_buckets(df, feature)\n",
    "    print(df.groupby(feature).quality.mean(), '\\n')\n",
    "```\n",
    "   \n",
    "output:\n",
    "    \n",
    "    \n",
    "fixed_acidity\n",
    "\n",
    "\n",
    "high    5.726061\n",
    "\n",
    "low     5.540052\n",
    "\n",
    "Name: quality, dtype: float64 \n",
    "\n",
    "\n",
    "volatile_acidity\n",
    "\n",
    "high    5.392157\n",
    "\n",
    "low     5.890166\n",
    "\n",
    "Name: quality, dtype: float64 \n",
    "\n",
    "\n",
    "etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Efficiency:\n",
    "\n",
    "reduces time and space in memory\n",
    "\n",
    "To make computations faster --> use vector operations (numpy) instead of loops\n",
    "\n",
    "Exaxmple: \n",
    "\n",
    "`np.intersect1d` is faster than looping through two df-s, but slower then `np.intersection` after conversion of the list/df/array to set\n",
    "\n",
    "\n",
    "`np.where` iterates through array elements that meet certain condition\n",
    "\n",
    "\n",
    "`total_price = np.where(gift_costs < 25).sum() * 1.08` instead of looping\n",
    "\n",
    "\n",
    "`df['first_name'], df['last_name'] = df['name'].str.split(' ', 1).str`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readme-s:\n",
    "\n",
    "At a minimum, this should explain what it does, list its dependencies, and provide sufficiently detailed instructions on how to use it.\n",
    "\n",
    "## CI\n",
    "\n",
    "https://algorithmia.com/blog/how-to-version-control-your-production-machine-learning-models\n",
    "\n",
    "\n",
    "\n",
    "### Merge Conflicts https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-merge-conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Driven Development and Data Science\n",
    "\n",
    "\n",
    "TEST DRIVEN DEVELOPMENT: a development process where you write tests for tasks before you even write the code to implement those tasks.\n",
    "\n",
    "UNIT TEST: a type of test that covers a “unit” of code, usually a single function, independently from the rest of the program.\n",
    "\n",
    "To install pytest, run pip install -U pytest in your terminal. Create a test file starting with test_.Define unit test functions that start with test_ inside the test file. Enter pytest into your terminal in the directory of your test file and it will detect these tests for you!\n",
    "\n",
    "test_ is the default - if you wish to change this, you can learn how to in this pytest configuration. In the test output, periods represent successful unit tests and F's represent failed unit tests. Since all you see is what test functions failed, it's wise to have only one assert statement per test. Otherwise, you wouldn't know exactly how many tests failed, and which tests failed.\n",
    "\n",
    "Your tests won't be stopped by failed assert statements, but it will stop if you have syntax errors.\n",
    "INTEGRATION TEST: To show that all the parts of our program work with each other properly, communicating and transferring data between them correctly, we use integration tests. https://www.fullstackpython.com/integration-testing.html\n",
    "\n",
    "Resources:\n",
    "\n",
    "Four Ways Data Science Goes Wrong and How Test Driven Data Analysis Can Help: Blog Post https://www.predictiveanalyticsworld.com/machinelearningtimes/four-ways-data-science-goes-wrong-and-how-test-driven-data-analysis-can-help/6947/\n",
    "\n",
    "\n",
    "Ned Batchelder: Getting Started Testing: Slide Deck and Presentation Video https://speakerdeck.com/pycon2014/getting-started-testing-by-ned-batchelder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging\n",
    "\n",
    "DEBUG - level you would use for anything that happens in the program.\n",
    "ERROR - level to record any error that occurs\n",
    "INFO - level to record all actions that are user-driven or system specific, such as regularly scheduled operations\n",
    "\n",
    "## Code Reviews\n",
    "\n",
    "https://www.fullstackpython.com/integration-testing.html\n",
    "\n",
    "https://github.com/lyst/MakingLyst/tree/master/code-reviews\n",
    "\n",
    "\n",
    "\n",
    "Is the code clean and modular?\n",
    "Can I understand the code easily?\n",
    "Does it use meaningful names and whitespace?\n",
    "Is there duplicated code?\n",
    "Can you provide another layer of abstraction?\n",
    "Is each function and module necessary?\n",
    "Is each function or module too long?\n",
    "\n",
    "\n",
    "Is the code efficient?\n",
    "Are there loops or other steps we can vectorize?\n",
    "Can we use better data structures to optimize any steps?\n",
    "Can we shorten the number of calculations needed for any steps?\n",
    "Can we use generators or multiprocessing to optimize any steps?\n",
    "\n",
    "\n",
    "Is documentation effective?\n",
    "Are in-line comments concise and meaningful?\n",
    "Is there complex code that's missing documentation?\n",
    "Do function use effective docstrings?\n",
    "Is the necessary project documentation provided?\n",
    "\n",
    "\n",
    "Is the code well tested?\n",
    "Does the code high test coverage?\n",
    "Do tests check for interesting cases?\n",
    "Are the tests readable?\n",
    "Can the tests be made more efficient?\n",
    "\n",
    "\n",
    "Is the logging effective?\n",
    "Are log messages clear, concise, and professional?\n",
    "Do they include all relevant and useful information?\n",
    "Do they use the appropriate logging level?\n",
    "\n",
    "\n",
    "Using linters: https://www.pylint.org/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Object Oriented Programming\n",
    "\n",
    "## (Project A: Create and Upload a Python Package to Pypi)\n",
    "## (Project B: Develop a Daa Dashboard Using Flask, Plotly and Pandas)\n",
    "## (Project C: Deploy a Data Dashboard)\n",
    "\n",
    "https://www.youtube.com/watch?v=Y8ZVw1LHI8E&feature=emb_logo\n",
    "\n",
    "https://www.youtube.com/watch?time_continue=279&v=NcgDIWm6iBA&feature=emb_logo\n",
    "\n",
    "- class - a blueprint consisting of methods and attributes\n",
    "- object - an instance of a class. It can help to think of objects as something in the real world like a yellow pencil, a small dog, a blue shirt, etc. However, as you'll see later in the lesson, objects can be more abstract.\n",
    "- attribute - a descriptor or characteristic. Examples would be color, length, size, etc. These attributes can take on specific values like blue, 3 inches, large, etc.\n",
    "- method - an action that a class or object could take\n",
    "- OOP - a commonly used abbreviation for object-oriented programming\n",
    "- encapsulation - one of the fundamental ideas behind object-oriented programming is called encapsulation: you can combine functions and data all into a single entity. In object-oriented programming, this single entity is called a class. Encapsulation allows you to hide implementation details much like how the scikit-learn package hides the implementation of machine learning algorithms.\n",
    "\n",
    "\n",
    "\n",
    "Function vs method --> method doesn't return anything\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A get method is for obtaining an attribute value. A set method is for changing an attribute value. If you were writing a Shirt class, the code could look like this:\n",
    "\n",
    "```\n",
    "class Shirt:\n",
    "\n",
    "    def __init__(self, shirt_color, shirt_size, shirt_style, shirt_price):\n",
    "        self._price = shirt_price\n",
    "\n",
    "    def get_price(self):\n",
    "      return self._price\n",
    "\n",
    "    def set_price(self, new_price):\n",
    "      self._price = new_price\n",
    "```\n",
    "\n",
    "This is a replacement for the ugly code such as here:\n",
    "\n",
    "```\n",
    "shirt_one.price = 10\n",
    "shirt_one.price = 20\n",
    "shirt_one.color = 'red'\n",
    "shirt_one.size = 'M'\n",
    "shirt_one.style = 'long_sleeve'\n",
    "```\n",
    "\n",
    "\n",
    "Instantiating and using an object might look like this:\n",
    "\n",
    "```\n",
    "shirt_one = Shirt('yellow', 'M', 'long-sleeve', 15)\n",
    "print(shirt_one.get_price())\n",
    "shirt_one.set_price(10)\n",
    "```\n",
    "\n",
    "\n",
    " Following the Python convention, the underscore in front of price is to let a programmer know that price should only be accessed with get and set methods rather than accessing price directly with shirt_one._price. However, a programmer could still access _price directly because there is nothing in the Python language to prevent the direct access.To reiterate, a programmer could technically still do something like shirt_one._price = 10, and the code would work. But accessing price directly, in this case, would not be following the intent of how the Shirt class was designed.\n",
    "\n",
    "Also, if you were developing a software program, you would want to modularize this code.\n",
    "\n",
    "You would put the Shirt class into its own Python script called, say, shirt.py. And then in another Python script, you would import the Shirt class with a line like: from shirt import Shirt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def display_sales(self):\n",
    "        \"\"\"The display_sales method prints out all pants that have been sold\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns: None\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        for pants in self.pants_sold:\n",
    "            print('color: {}, waist_size: {}, length: {}, price: {}'\\\n",
    "                  .format(pants.color, pants.waist_size, pants.length, pants.price))\n",
    "    \n",
    "    def calculate_sales(self):\n",
    "        \"\"\"The calculate_sales method sums the total price of all pants sold\n",
    "\n",
    "        Args: None\n",
    "\n",
    "        Returns:\n",
    "            float: sum of the price for all pants sold\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        total = 0\n",
    "        for pants in self.pants_sold:\n",
    "            total += pants.price\n",
    "            \n",
    "        self.total_sales = total\n",
    "        \n",
    "        return total\n",
    "    \n",
    "    def calculate_commission(self, percentage):\n",
    "        \"\"\"The calculate_commission method outputs the commission based on sales\n",
    "\n",
    "        Args:\n",
    "            percentage (float): the commission percentage as a decimal\n",
    "\n",
    "        Returns:\n",
    "            float: the commission due\n",
    "        \"\"\"\n",
    "\n",
    "        sales_total = self.calculate_sales()\n",
    "        return sales_total * percentage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Magic methods\n",
    "\n",
    "`__add__` changes the behavior of the plus sign\n",
    "\n",
    "`__repr__`  \n",
    "\n",
    "\n",
    "## 2.2 \n",
    "\n",
    "## 2.3 Multiple Inheritance, Mixins\n",
    "\n",
    "https://easyaspython.com/mixins-for-fun-and-profit-cb9962760556\n",
    "\n",
    "## 2.4 Decorators\n",
    "\n",
    "https://realpython.com/primer-on-python-decorators/\n",
    "\n",
    "\n",
    "## 2.5 Organizing into Modules\n",
    "\n",
    "module = reusable file\n",
    "\n",
    "package = collection o fmodules placed into a directory, also needs an __init__.py file.\n",
    "\n",
    "accessing installed packages by `{name_of_the_package}.__file__` outputs the whole path in the machine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data Engineering\n",
    "\n",
    "In this project you're going to be analyzing thousands of real messages provided by Figure 8, sent during natural disasters either via social media or directly to disaster response organizations. You'll build an ETL pipeline that processes message and category data from csv files and load them into a SQLite database, which your machine learning pipeline will then read from to create and save a multi-output supervised learning model. Then, your web app will extract data from this database to provide data visualizations and use your model to classify new messages for 36 categories.\n",
    "\n",
    "Machine learning is critical to helping different organizations understand which messages are relevant to them and which messages to prioritize. During these disasters is when they have the least capacity to filter out messages that matter, and find basic methods such as using key word searches to provide trivial results. In this course, you'll learn the skills you need in ETL pipelines, natural language processing, and machine learning pipelines to create an amazing project with real world significance.\n",
    "\n",
    "\n",
    "3.1 ETL / ELT\n",
    "\n",
    "3.2 Encoding\n",
    "\n",
    "This link has a list of encodings that Python recognizes https://docs.python.org/3/library/codecs.html#standard-encodings\n",
    "\n",
    "OR \n",
    "\n",
    "```\n",
    "!pip install chardet\n",
    "\n",
    "with open(\"mystery.csv\", 'rb') as file:\n",
    "    print(chardet.detect(file.read()))\n",
    "    \n",
    "```\n",
    "\n",
    "3.3 Missing values\n",
    "\n",
    "There are also implementations of some machine learning algorithms, such as gradient boosting decision trees that can handle missing values https://xgboost.readthedocs.io/en/latest/\n",
    "\n",
    "Options to handle missing data:\n",
    "\n",
    "- delete\n",
    "- impute (replace by the ean e.g., or median..)\n",
    "- forward fill, backward fill (with time related data)\n",
    "\n",
    "\n",
    "3.4 Scaling Data\n",
    "\n",
    "Some ML algorithms work better with scaled data (PCA, LR..)\n",
    "\n",
    "normalization/feature scaling: rescaling (numerical data on a scale from 0 to 1), standardizations (mean = 0, stdev = 1)\n",
    "\n",
    "\n",
    "3.5 Feature Engineering\n",
    "\n",
    "useful if modesl are uderfitting\n",
    "\n",
    "\n",
    "3.6 Outliers\n",
    "\n",
    "Statistical Methods for Outlier Detection: z-scores, Turkey Method (mean, stdev, quartiles..) Like so:\n",
    "\n",
    "\n",
    "Use the Tukey rule to determine what values of the population data are outliers for the year 2016. The Tukey rule finds outliers in one-dimension. The steps are:\n",
    "```\n",
    "Find the first quartile (ie .25 quantile)\n",
    "Find the third quartile (ie .75 quantile)\n",
    "Calculate the inter-quartile range (Q3 - Q1)\n",
    "Any value that is greater than Q3 + 1.5 * IQR is an outlier\n",
    "Any value that is less than Q1 - 1.5 * IQR is an outlier\n",
    "\n",
    "Calculate the maximum value and minimum values according to the Tukey rule: max_value is Q3 + 1.5 * IQR while min_value is Q1 - 1.5 * IQR`\n",
    "\n",
    "\n",
    "max_value = \n",
    "min_value = \n",
    "\n",
    "\n",
    "TODO: filter the population_2016 data for population values that are greater than max_value or less than min_value\n",
    "```\n",
    "\n",
    "Possible to transpose 3-D data to 2 D by using  a PCA method so that it's easier to spot visually on a line/parabola, or to cluster data and measure distance of pointfrom a centroid\n",
    "\n",
    "https://towardsdatascience.com/a-brief-overview-of-outlier-detection-techniques-1e0b2c19e561\n",
    "\n",
    "https://scikit-learn.org/stable/modules/outlier_detection.html\n",
    "\n",
    "\n",
    "ONLY remove if the outlier affects model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Submit a package\n",
    "\n",
    "Packaging and distributing projects¶\n",
    "\n",
    "### Udacity video class is here: https://www.youtube.com/watch?time_continue=394&v=4uosDOKn5LI&feature=emb_logo\n",
    "\n",
    "\n",
    "\n",
    "https://packaging.python.org/tutorials/packaging-projects/\n",
    "\n",
    "\n",
    "Github contribution:\n",
    "\n",
    "https://akrabat.com/the-beginners-guide-to-contributing-to-a-github-project/\n",
    "\n",
    "https://github.com/MarcDiethelm/contributing/blob/master/README.md\n",
    "\n",
    "\n",
    "### PyPi vs. Test PyPi\n",
    "\n",
    "Note that pypi.org and test.pypy.org are two different websites. You'll need to register separately at each website. If you only register at pypi.org, you will not be able to upload to the test.pypy.org repository.\n",
    "\n",
    "Also, remember that your package name must be unique. If you use a package name that is already taken, you will get an error when trying to upload the package.\n",
    "\n",
    "Summary of the Terminal Commands Use\n",
    "\n",
    "```\n",
    "# just navigate to the stage in your directory that contains your package and setup.py file\n",
    "\n",
    "cd binomial_package_files \n",
    "                    \n",
    "                    \n",
    "# creates important files necessary for the package submission                    \n",
    "python setup.py sdist \n",
    "\n",
    "# lib for package submission, that creates a .tar.gz file that should be submitted to PyPI\n",
    "pip install twine \n",
    "\n",
    "# commands to upload to the pypi test repository\n",
    "twine upload --repository-url https://test.pypi.org/legacy/ dist/*\n",
    "pip install --index-url https://test.pypi.org/simple/ dsnd-probability\n",
    "\n",
    "\n",
    "# command to upload to the pypi repository\n",
    "twine upload dist/*\n",
    "pip install dsnd-probability\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Then you ideally create a separate venv and install the package as normally. I had to install my oop_guessing_game package as following:\n",
    "\n",
    "`pip install oop_guessing_game`\n",
    "\n",
    "and import it as below:\n",
    "\n",
    "`from oop_guessing_game.oop_guessing_game import ComputerPlayer, PersonPlayer, Game`\n",
    "\n",
    "\n",
    "\n",
    "More PyPi Resources\n",
    "\n",
    "Tutorial on distributing packages https://packaging.python.org/tutorials/packaging-projects/\n",
    "\n",
    "This link has a good tutorial on distributing Python packages including more configuration options for your setup.py file: tutorial on distributing packages. You'll notice that the python command to run the setup.py is \n",
    "slightly different with\n",
    "\n",
    "python3 setup.py sdist bdist_wheel\n",
    "This command will still output a folder called dist. The difference is that you will get both a .tar.gz file and a .whl file. The .tar.gz file is called a source archive whereas the .whl file is a built distribution. The .whl file is a newer type of installation file for Python packages. When you pip install a package, pip will first look for a whl file (wheel file) and if there isn't one, will then look for the tar.gz file.\n",
    "\n",
    "A tar.gz file, ie an sdist, contains the files needed to compile and install a Python package. A whl file, ie a built distribution, only needs to be copied to the proper place for installation. Behind the scenes, pip installing a whl file has fewer steps than a tar.gz file.\n",
    "\n",
    "Other than this command, the rest of the steps for uploading to PyPi are the same.\n",
    "\n",
    "Other Links\n",
    "If you'd like to learn more about PyPi, here are a couple of resources:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Web Development\n",
    "\n",
    "## (Develop and Deploy Dashboard Project)\n",
    "\n",
    "\n",
    "- setting up the backend\n",
    "- linking the backend and the frontend together\n",
    "- deploying the app to a server so that the app is available from a web address\n",
    "\n",
    "\n",
    "Why Bootstrap?\n",
    "Bootstrap is one of the easier front-end frameworks to work with. Bootstrap eliminates the need to write CSS or JavaScript. Instead, you can style your websites with HTML. You'll be able to design sleek, modern looking websites more quickly than if you were coding the CSS and JavaScript directly.\n",
    "\n",
    "https://getbootstrap.com/docs/4.0/getting-started/introduction/#starter-template\n",
    "\n",
    "https://getbootstrap.com/docs/4.0/layout/grid/\n",
    "\n",
    "https://getbootstrap.com/docs/4.0/layout/overview/\n",
    "\n",
    "https://getbootstrap.com/docs/4.0/content/images/\n",
    "\n",
    "https://getbootstrap.com/docs/4.0/components/navbar/\n",
    "\n",
    "https://getbootstrap.com/docs/4.0/utilities/colors/\n",
    "\n",
    "\n",
    "\n",
    "### Javascript\n",
    "\n",
    "Jquery came out in 2006. There are newer JavaScript tools out there like React and Angular.\n",
    "\n",
    "\n",
    "Difficult to code, using JQuery instead, just need to reference it  in the code by inputing:\n",
    "\n",
    "```\n",
    "<script\n",
    "src = \"https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js\">\n",
    "</script>\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Basic JavaScript Syntax\n",
    "\n",
    "Here are a few rules to keep in mind when writing JavaScript:\n",
    "\n",
    "- a line of code ends with a semi-colon ;\n",
    "- () parenthesis are used when calling a function much like in Python\n",
    "- {} curly braces surround large chunks of code or are used when initializing dictionaries\n",
    "- [] square brackets are used for accessing values from arrays or dictionaries much like in Python\n",
    "\n",
    "\n",
    "Here is an example of a JavaScript function that sums the elements of an array.\n",
    "\n",
    "```\n",
    "function addValues(x) {\n",
    "  var sum_array = 0;\n",
    "  for (var i=0; i < x.length; i++) {   \n",
    "    sum_array += x[i];\n",
    "  }\n",
    "  return sum_array;\n",
    "}\n",
    "\n",
    "addValues([3,4,5,6]);\n",
    "```\n",
    "\n",
    "### Flask (BE Deployment of Web App)\n",
    "\n",
    "Flask. A web framework takes care of all the routing needed to organize a web page so that you don't have to write the code yourself!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "The 3 stages of an NLP pipeline are: Text Processing > Feature Extraction > Modeling.\n",
    "\n",
    "Text Processing: Take raw input text, clean it, normalize it, and convert it into a form that is suitable for feature extraction.\n",
    "Feature Extraction: Extract and produce feature representations that are appropriate for the type of NLP task you are trying to accomplish and the type of model you are planning to use.\n",
    "Modeling: Design a statistical or machine learning model, fit its parameters to training data, use an optimization procedure, and then use it to make predictions about unseen data.\n",
    "This process isn't always linear and may require additional steps.\n",
    "\n",
    "\n",
    "### Data Preparation:\n",
    "\n",
    "- Cleaning to remove irrelevant items, such as HTML tags (regular expression)\n",
    "- Normalizing by converting to all lowercase and removing punctuation (`.lower()`)\n",
    "- Splitting text into words or tokens (`.split()`) OR (`from nltk.tokenize import word_tokenize`, more cleaning in the tokenize package. Or `...import sent_tokenize` splits words into sentences 1 sentence being 1 token)\n",
    "- Removing words that are too common, also known as stop words `from nltk.corpus import stopwords` AND THEN: words = `[w for w in words if w not in stopwords.words('english')]`\n",
    "- Identifying different parts of speech and named entities `fromnltk import pos_tag`\n",
    "- Converting words into their dictionary forms, using stemming and lemmatization (`[PorterStemmer().stem(w) for w in words]`) AND `[WordNetLemmatizer().lemmatize(w) for w  in words]`\n",
    "\n",
    "\n",
    "## Feature Extraction\n",
    "\n",
    "- Bag of Words (a set of words in text, turned into a vector of numbers: collect vocabulary from different sources we are comparing, each word being one column, claculate occurence in each of the sources of this word while each source being one row and make a document-term matrix each number beaing a document word frequency. The greater the dot product (sum of all occurences), the bigger the similarity.\n",
    "\n",
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
